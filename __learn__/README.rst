Python Vertex AI SDK
=======================

|GA|  |pypi|  |versions|  |unit-tests|  |system-tests|  |sample-tests|

`Vertex AI`_: This is a collection of ML tools and services for building ML models with AutoML or custom code. This is the best workbench for both beginners and experts for the entire ML development lifecycle.

- `Client Library Docs`_
- `Product Docs`_

.. |GA| image:: https://img.shields.io/badge/support-ga-gold.svg
   :target: https://github.com/googleapis/google-cloud-python/blob/main/README.rst#general-availability
.. |pypi| image:: https://img.shields.io/pypi/v/google-cloud-aiplatform.svg
   :target: https://pypi.org/project/google-cloud-aiplatform/
.. |versions| image:: https://img.shields.io/pypi/pyversions/google-cloud-aiplatform.svg
   :target: https://pypi.org/project/google-cloud-aiplatform/
.. |unit-tests| image:: https://storage.googleapis.com/cloud-devrel-public/python-aiplatform/badges/sdk-unit-tests.svg
   :target: https://storage.googleapis.com/cloud-devrel-public/python-aiplatform/badges/sdk-unit-tests.html
.. |system-tests| image:: https:://storage.googleapis.com/cloud-devrel-public/python-aiplatform/badges/sdk-system-tests.svg
   :target: https://storage.googleapis.com/cloud-devrel-public/python-aiplatform/badges/sdk-system-tests.html
.. |sample-tests| image:: https://storage.googleapis.com/cloud-devrel-public/python-aiplatform/badges/sdk-sample-tests.svg
   :target: https://storage.googleapis.com/cloud-devrel-public/python-aiplatform/badges/sdk-sample-tests.html
.. _Vertex AI: https://cloud.google.com/vertex-ai/docs
.. _Client Library Documentation: https://cloud.google.com/python/docs/reference/aiplatform/latest
.. _Product Documentation: https://cloud.google.com/vertex-ai/docs

Getting Started
---------------

Do this:

1. `Choose/create a Cloud Platform Project`_
2. `Turn on your project's billing`_
3. `Turn on Vertext AI API`_
4. `Turn on authentication`_

.. _`Choose/create a Cloud Platform Project`: https://console.cloud.google.com/project
.. _`Turn on your project's billing`: https://cloud.google.com/billing/docs/how-to/modify-project#enable_billing_for_a_project
.. _`Turn on Vertext AI API`: https://cloud.google.com/vertex-ai/docs/start/use-vertex-ai-python-sdk
.. _`Turn on authentication`: https://googleapis.dev/python/google-api-core/latest/auth.html

Install
~~~~~~~
Using pip, install this library in a `virtualenv`_ (create Python environments that are isolated) - manage dependencies and versions, as well as indirect permissionsa. We won't come into conflict with installed system dependencies, and we won't need install permissions.

.. _virtualenv: https://virtualenv.pypa.io/en/latest/

\*nix
^^^^^

.. code-block:: console

  pip install virtualenv
  virtualenv <name-of-env>
  source <name-of-env>/bin/activate
  <name-of-env>/bin/pip install google-cloud-aiplatform

Windows
^^^^^^^

.. code-block:: console

  pip install virtualenv
  virtualenv <name-of-windows-env>
  <name-of-windows-env>\Scripts\activate
  <name-of-windows-env>\Scripts\pip.exe install google-cloud-aiplatform

 Use Python 3.8 and above.

 For Python 3.6 use v1.12.1 of this library.

Overview
~~~~~~~~
Check `vertex-ai-samples`_ for examples.

.. _vertex-ai-samples: https://github.com/GoogleCloudPlatform/vertex-ai-samples/tree/main/notebooks/community/sdk

All SDK features are visible in the :code:`google/cloud/aiplatform` folder.
The underlying engine of the Vertex SDK is GAPIC (Google API CodeGen). The library is located in :code:`google/cloud/aiplatform_v1` and :code:`google/cloud/aiplatform_v1beta1`, autogenerated from Google service proto files.

Use this procedure to figure out which libraries to use:
1. Examine :code:`google/cloud/aiplatform` - Vertex SDK APIs are recommended over GAPIC
2. If you haven't found what you're looking for, go through :code:`aiplatform_v1` to see if there is a GAPIC equivalent
3. You can also check :code:`aiplatform_v1beta`

Send through a GitHub feature request if you can't find what you want.

Using Vertex AI SDK
^^^^^^^^^^^^^^^^^^^
Use this default namespace for most tasks regarding SDK resources:

.. code-block:: Python
    
    from google.cloud import aiplatform

For SDK preview features, this namespace works:

.. code-block:: Python

    from vertexai import preview

For GA features use this namespace:

.. code-block:: Python

    import vertexai

Initialisation
^^^^^^^^^^^^^^
Configure the SDK to set commonly used state.

.. code-block:: Python

    aiplatform.init(
      # GCP project info
      project='some-project',

      # region
      location='us-central1',

      # regional Cloud Storage bucket
      staging_bucket='gs://some_staging_bucket',

      # custom google.auth.credentials.Credentials
      # this is the default if it's not specified
      credentials=some_credentials,

      # CMEK resource name, if any, will be applied to all Vertex AI resources
      encryption_spec_key_name=some_encryption_key_name,

      # experiment name for tracking logged metrics and parameters
      experiment='some-experiment',

      # experiment's description
      experiment_description='Some Description of Experiment'
    
    )

Datasets
^^^^^^^^
Vertex AI manages tabular, text, image and video datasets. They can be used downstream to train models via the SDK.

Tabular dataset creation: 

.. code-block:: Python

    my_dataset = aitplatform.TabularDataset.create(
      display_name="some-dataset", gcs_source=['gs://bucket/path/some-dataset.csv']
    )

Create and import separately:

.. code-block:: Python

    from google.cloud import aiplatform

    some_dataset = aiplatform.TextDataset.create(
      display_name="some-dataset"
    )

    some_dataset.import_data(
      gcs_source=['gs://path/to/bucket/some_dataset.csv'],
      import_schema_uri=aiplatform.schema.dataset.ioformat.text.multi_label_classification
    )

Retrieve previously created dataset:

.. code-block:: Python

    dataset = aiplatform.ImageDataset('projects/some-project/location/us-central1/datasets/{DATASET_ID}')

All the dataset schemas that Vertex AI supports can be found in the :code:`aiplatform.schema.dataset` namespace, Please see `Preparing data docs`_.

.. _Preparing data docs: https://cloud.google.com/ai-platform-unified/docs/datasets/prepare

Train Models
^^^^^^^^^^^^
With Vertex AI we can train Custom and AutoML models.

Custom model training can be performed with custom Python scripts, custom Python package or container.

**Custom code prep**
With Vertex AI custom training we can train on datasets and produce Vertex AI models. Your script must:

→ read datasets from environment variables set from the training service: 

.. code-block:: Python

  os.environ['AIP_DATA_FORMAT']         # indicates format of data
  os.environ['AIP_TRAINING_DATA_URI']   # training split uri
  os.environ['AIP_VALIDATION_DATA_URI'] # validation split uri
  os.environ['AIP_TEST_DATA_URI']       # test split uri

For more info, check out `Using a managed dataset in a custom training application`_

.. _Custom training apps involving managed datasets: https://cloud.google.com/vertex-ai/docs/training-using-managed-datasets

→ write model artifact to the environment variable set by the training service:

.. code-block:: Python

  os.environ['AIP_MODEL_DIR']

**Training models**

.. code-block:: Python

  job = aiplatform.CustomTrainingJob(
      display_name="some-training-job",
      script_path="training_script.py",
      container_uri="us-docker.pkg.dev/vertex-ai/training/tf-cpu.2.2:latest",
      requirements=["gcfs==0.7.1"],
      model_serving_container_image_uri="us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2.2:latest",
  )

  model = job.run(some_dataset,
      replica_count=1,
      machine_Type="n1-standard-4",
      accelerator_type='NVIDIA_TESLA_K80',
      accelerator_count=1)

Notes: `some_dataset` is a created managed dataset (as per above); `model` is an exportable or deployable Vertex AI model.

AutoML
------
Tabular, image, text, video and forecasting-based AutoML is available via Vertex AI SDK.

Train:
.. code-block:: Python

  dataset = aiplatform.TabularDataset('projects/my-project/location/us-central1/datasets/{DATASET_ID}')

  job = aiplatform.AutoMLTabularTrainingJob(
    display_name="train-automl",
    optimization_prediction_type="regression",
    optimization_objective="minimize-rmse",
  )

  model = job.run(
    dataset=dataset,
    target_column="some_target_column",
    training_fraction_split=0.6,
    validation_fraction_split=0.2,
    test_fraction_split=0.2,
    budget_milli_node_hours=1000,
    model_display_name="some-automl-model",
    disable_early_stopping=False,
  )


Getting a model:

.. code-block:: Python

  model = aiplatform.Model('/projects/some-project/locations/us-central1/models/{MODEL_ID}')


Upload model:

.. code-block:: Python
  model = aiplatform.Model.upload(
    display_name='some-model',
    artifact_uri='gs://path/to/model/dir',
    serving_container_image_uri='us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-2:latest'
  )

Deploy model:

.. code-block:: Python
  
  endpoint = model.deploy(machine_type="n1-standard-4",
    min_replica_count=1,
    max_replica_count=5,
    machine_type='n1-standard-4',
    accelerator_type='NVIDIA_TESLA_K80',
    accelerator_count=1)

Check out `Importing models to Vertex AI`_ for more info.

.. _Importing models to Vertex AI: https://cloud.google.com/vertex-ai/docs/general/import-model

Evaluation of models
--------------------

You can get model evaluation metrics for all AutoML models.

List all model evaluations:

.. code-block:: Python

  model = aiplatform.Model('projects/some-project/locations/us-central1/models/{MODEL_ID}')
  evaluations = model.list_model_evaluations()

Get evaluation resource for a given model:

.. code-block:: Python

  model = aiplatform.Model('projects/some-project/locations/us-central1/models/{MODEL_ID}')

  # first evaluation with no args is returned; evaluation ID can also be passed in
  evaluation = model.get_model_evaluation()
  eval_metrics = evaluation.metrics

Create a direct reference to your model evaluation via feeding in the resource name of the model evaluation:

.. code-block:: Python

  evaluation = aiplatform.ModelEvaluation(
    evaluation_name = 'projects/some-project/locations/us-central1/models/{MODEL_ID}/evaluations/{EVALUATION_ID}'
  )

Create a reference to the evaluation via model and evaluation IDs as parameters:

.. code-block:: Python

  evaluation = aiplatform.ModelEvaluation(
    evaluation_name={EVALUATION_ID},
    model_id={MODEL_ID}
  )

Batch Prediction
----------------

Create a batch prediction job:

.. code-block:: Python

  model = aiplatform.Model('/projects/some-project/locations/us-central1/models/{MODEL_ID}')

  batch_prediction_job = model.batch_predict(
    job_display_name='some-batch-prediction-job',
    instances_format='csv',
    machine_type='n1-standard-4',
    gcs_source=['gs://path/to/some-file.csv'],
    gcs_destination_prefix='gs://path/to/batch_prediction_results/',
    service_account='some-sa@some-project.iam.gserviceaccount.com'
  )

Async version of batch prediction:

.. code-block:: Python

  job = model.batch_predict(..., sync=False)

  # create resource and wait
  job.wait_for_resource_creation()

  # retrieve state
  job.state

  # block till job is complete
  job.wait()

Endpoints
---------

Create endpoint:

.. code-block:: Python

  endpoint = aiplatform.Endpoint.create(display_name='some-endpoint')

Deploy model to created endpoint:

.. code-block:: Python

  model = aiplatform.Model('/projects/some-project/locations/us-central1/models/{MODEL_ID}')

  endpoint.deploy(model,
    min_replica_count=1,
    max_replica_count=5m
    machine_type='n1-standard-4',
    accelerator_type='NVIDIA_TESLA_K80',
    accelerator_count=1)

Retrieving predictions from endpoints:

.. code-block:: Python

  endpoint.predict(instances=[6.7, 3.1, 4.7, 1.5], [4.6, 3.1, 1.5, 0.2])

Reverse endpoint model deployments:

.. code-block:: Python

  endpoint.undeploy_all()

Removing endpoint:

.. code-block:: Python

  endpoint.delete()

Now about pipelines!
--------------------

Create a pipeline run and monitor till it's complete:

.. code-block:: Python

  # Instantiate
  pipeline = PipelineJob(display_name="Some pipeline, ya",

    # Shall we cache? If so pipeline step result is always cached, if not, then never
    # So True or False. If set to None, then we defer to cache option for each pipeline component as per the pipeline definition
    enable_caching=False,

    # Local/GCS path to compiled pipeline definition
    template_path="pipeline.json",

    # Pipeline input parameters dictionary
    parameter_values=parameter_values,

    # Pipeline root (GCS path)
    pipeline_root=pipeline_root,)

  # Run pipeline in Vertex AI and monitor till it's documentation
  pipeline.run(service_account=service_account, # service account email address; need iam.serviceAccounts.actAs permission on the service account
    sync=True) # synchronous (wait) option; false/async returns the function call immediately

If we want to create a Vertex AI Pipeline that doesn't have monitoring till completion, choose `submit`, not `run`:

.. code-block:: Python

  # Instantiate
  job = PipelineJob(display_name="some pipeline!",
      enable_caching=False,
      template_path="pipeline.json",
      parameter_values=parameter_values,
      pipeline_root=pipeline_root,)

  job.submit(service_account=service_account,)

Get Metadata - Explainable AI
-----------------------------

TF 1 models metadata retrieval:

.. code-block:: Python

  from google.cloud.aiplatform.explain.metadata.tf.v1 import saved_model_metedata_builder

  builder = saved_model_metadata_builder.SavedModelMetadataBuilder(
    'gs://python/path/to/model/dir',
    tags=[tf.saved_model.tag_constansts.SERVING]
  )
  generated_metadata = builder.get_metadata()

  